{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_curve,roc_auc_score\n",
    "from statsmodels.discrete import discrete_model as sm\n",
    "from statsmodels.tools.tools import add_constant\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binary dataset\n",
    "data_default = pd.read_excel(\"Default.xlsx\")\n",
    "\n",
    "# Lets keep it to 2 variables only\n",
    "\n",
    "# convert student column to categorical\n",
    "\n",
    "data_default[\"default\"] = data_default[\"default\"].replace(\"No\",0)\n",
    "data_default[\"default\"] = data_default[\"default\"].replace(\"Yes\",1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Peek into the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>default</th>\n",
       "      <th>student</th>\n",
       "      <th>balance</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>729.526495</td>\n",
       "      <td>44361.625074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>817.180407</td>\n",
       "      <td>12106.134700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>1073.549164</td>\n",
       "      <td>31767.138947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>529.250605</td>\n",
       "      <td>35704.493935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>785.655883</td>\n",
       "      <td>38463.495879</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   default student      balance        income\n",
       "1        0      No   729.526495  44361.625074\n",
       "2        0     Yes   817.180407  12106.134700\n",
       "3        0      No  1073.549164  31767.138947\n",
       "4        0      No   529.250605  35704.493935\n",
       "5        0      No   785.655883  38463.495879"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_default.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    9667\n",
       "1     333\n",
       "Name: default, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Quite an imbalanced Dataset\n",
    "data_default[\"default\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split dataset into x and y\n",
    "\n",
    "y_default = data_default['default']\n",
    "x_default = data_default.drop([\"default\",\"student\"],axis =1)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "st = StandardScaler()\n",
    "x_default = st.fit_transform(x_default)\n",
    "\n",
    "# split into training and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_x_def,test_x_def,train_y_def,test_y_def = train_test_split(x_default,y_default,test_size = 0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate model, fit and predict\n",
    "log_model = LogisticRegression(C=0.0001)\n",
    "log_model.fit(train_x_def,train_y_def) # log_model(y_train,x_Train).fit()\n",
    "prediction_sk = log_model.predict(train_x_def) # predicted classes\n",
    "prediction_probs = log_model.predict_proba(train_x_def) # probability values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      1.00      0.98      7736\n",
      "          1       0.00      0.00      0.00       264\n",
      "\n",
      "avg / total       0.94      0.97      0.95      8000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/uday/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print((classification_report(train_y_def, prediction_sk)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probability Threshold Adjustment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_45 = []\n",
    "for i in prediction_probs[:,1]:\n",
    "    if i>= 0.45:\n",
    "        threshold_45.append(1)\n",
    "    else:\n",
    "        threshold_30.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      1.00      0.99      7736\n",
      "          1       0.81      0.19      0.31       264\n",
      "\n",
      "avg / total       0.97      0.97      0.96      8000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(train_y_def,threshold_45))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upsampling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample \n",
    "\n",
    "# Separate majority and minority classes\n",
    "df_majority = data_default[data_default.default==0]\n",
    "df_minority = data_default[data_default.default==1]\n",
    " \n",
    "# Upsample minority class\n",
    "df_minority_upsampled = resample(df_minority, \n",
    "                                 replace=True,     # sample with replacement\n",
    "                                 n_samples=9667,    # to match majority class\n",
    "                                 random_state=123) # reproducible results\n",
    " \n",
    "# Combine majority class with upsampled minority class\n",
    "df_upsampled = pd.concat([df_majority, df_minority_upsampled])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    9667\n",
       "0    9667\n",
       "Name: default, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_upsampled.default.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-split into test and train\n",
    "\n",
    "y_default_up = df_upsampled['default']\n",
    "x_default_up = df_upsampled.drop([\"default\",\"student\"],axis =1)\n",
    "\n",
    "train_x_up,test_x_up,train_y_up,test_y_up = train_test_split(x_default_up,y_default_up,test_size = 0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-fit data to same model\n",
    "\n",
    "log_model.fit(train_x_up,train_y_up) # log_model(y_train,x_Train).fit()\n",
    "prediction_up = log_model.predict(train_x_up) # predicted classes\n",
    "prediction_probs_up = log_model.predict_proba(train_x_up) # probability values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.67      0.74      7726\n",
      "          1       0.72      0.86      0.78      7741\n",
      "\n",
      "avg / total       0.77      0.76      0.76     15467\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print((classification_report(train_y_up, prediction_up)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall Accuracy has fallen but much better performance on minority class. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = SMOTE(ratio='auto', kind='regular')\n",
    "X_resampled , y_resampled = sm.fit_sample(train_x_def, train_y_def)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15472"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit model with new data\n",
    "    \n",
    "log_model.fit(X_resampled,y_resampled)\n",
    "prediction_smote = log_model.predict(X_resampled) # predicted classes\n",
    "prediction_smote_probs = log_model.predict_proba(X_resampled) # probability values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      0.62      0.76      7736\n",
      "          1       0.72      0.99      0.84      7736\n",
      "\n",
      "avg / total       0.85      0.81      0.80     15472\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_resampled, prediction_smote))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Much Better!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
